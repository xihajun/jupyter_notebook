{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple parallel code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Vectorisation\n",
    "\n",
    "Vectorisation is straightforward in python (and R). You should always try to code with vectors/arrays, though For loops are sometimes necessary.\n",
    "\n",
    "In python:\n",
    "\n",
    "* For loops aren't intrinsically worse, but they encourage poor coding practice.\n",
    "\n",
    "In R: \n",
    "\n",
    "* For loops are very inefficient. For efficiency you may have to go out of your way to vectorise.\n",
    "\n",
    "In C/C++:\n",
    "\n",
    "* OpenMP allows for loops to be parallelised without any additional effort - just remember to avoid using the results of previous loops.\n",
    "* Modern updates (from C++-11) include many explicit vectorisations, allowing map/reduce vectorisations to be exploited directly.\n",
    "\n",
    "First, an array representation reminder in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "b =\n",
      "[[1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.array([[1,1],[1,1]])\n",
    "print(\"a =\")\n",
    "print(a)\n",
    "print(\"b =\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + b =\n",
      "[[2 3]\n",
      " [4 5]]\n",
      "a - b =\n",
      "[[0 1]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "# substraction and addition\n",
    "\n",
    "print(\"a + b =\")\n",
    "print(a + b)\n",
    "print(\"a - b =\")\n",
    "print(a - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a * b =\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "print(\"a * b =\")\n",
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a@b =\n",
      "[[3 3]\n",
      " [7 7]]\n",
      "np.dot(a,b) =\n",
      "[[3 3]\n",
      " [7 7]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "print(\"a@b =\")\n",
    "print(a@b)\n",
    "print(\"np.dot(a,b) =\")\n",
    "print(np.dot(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c.shape =\n",
      "(3,)\n",
      "d.shape\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "# numpy array with one row\n",
    "c =  np.array([1,2,3])\n",
    "print(\"c.shape =\")\n",
    "print(c.shape)\n",
    "# numpy array with three rows\n",
    "d = np.array([[1],[2],[3]])\n",
    "print(\"d.shape\")\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "first element in the array, e[0,0] =\n",
      "1\n",
      "first row of the array. e[0,:] =\n",
      "[1 2 3]\n",
      "second coulumn of the array. e[:,1] =\n",
      "[2 5 8]\n"
     ]
    }
   ],
   "source": [
    "# Define an 3x3 2d array\n",
    "e = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(e)\n",
    "print(\"first element in the array, e[0,0] =\")\n",
    "print(e[0,0])\n",
    "print(\"first row of the array. e[0,:] =\")\n",
    "print(e[0,:])\n",
    "print(\"second coulumn of the array. e[:,1] =\")\n",
    "print(e[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll make a simulation to compare between vectorised and non-vectorised code. This is just a simple matrix times vector computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create some test data and simulate results\n",
    "N=100000# Number of rows\n",
    "K=100 # Number of columns\n",
    "X = np.random.randn(N,K)\n",
    "W = np.random.rand(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_times_vector_forloop(X,W):\n",
    "    N,K=X.shape\n",
    "    # Initialize theta\n",
    "    forloop = []\n",
    "    for i in range(N):\n",
    "        hypo_i = 0\n",
    "        for j in range(K):\n",
    "            hypo_i += W[j]*X[i,j]\n",
    "        forloop.append(hypo_i)\n",
    "    return(forloop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.33 s, sys: 45.7 ms, total: 4.38 s\n",
      "Wall time: 4.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "forloop=matrix_times_vector_forloop(X,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 ms, sys: 2.47 ms, total: 14.7 ms\n",
      "Wall time: 9.36 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# matrix format\n",
    "vect = X@W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for loop\n",
      "[2.2873055232600876, -1.0296846002912856, 3.895888691012576, 4.7246531820039035]\n",
      "vectorised\n",
      "[ 2.28730552 -1.0296846   3.89588869  4.72465318]\n"
     ]
    }
   ],
   "source": [
    "## Check the answers\n",
    "print(\"for loop\")\n",
    "print(forloop[0:4])\n",
    "print(\"vectorised\")\n",
    "print(vect[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHALLENGE:  Make a plot of how the two approaches change in performance as a function of N (and/or K). What is the computational scaling?\n",
    "\n",
    "See https://towardsdatascience.com/vectorization-implementation-in-machine-learning-ca652920c55d for an example that is much more extreme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accumulate example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = np.random.randint(0, 100, size=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumsum_diff_with_accumulate(x):\n",
    "     x = np.asarray(x)\n",
    "     return np.max(x - np.minimum.accumulate(x))\n",
    "def cumsum_diff(x):\n",
    "     max_px = 0\n",
    "     min_px = x[0]\n",
    "     for px in x[1:]:\n",
    "         min_px = min(min_px, px)\n",
    "         max_px = max(px - min_px, max_px)\n",
    "     return max_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 588 ms, sys: 5.35 ms, total: 594 ms\n",
      "Wall time: 597 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cumsum_diff(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.8 ms, sys: 8.69 ms, total: 19.5 ms\n",
      "Wall time: 18 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cumsum_diff_with_accumulate(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Mapping python (and R) is straightfoward. \n",
    "\n",
    "http://chryswoods.com/parallel_python/map.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calc_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Function to calculate and return the distance between\n",
    "    two points\n",
    "    \"\"\"\n",
    "    \n",
    "    dx2 = (point1[0] - point2[0]) ** 2\n",
    "    dy2 = (point1[1] - point2[1]) ** 2\n",
    "    dz2 = (point1[2] - point2[2]) ** 2\n",
    "    return math.sqrt(dx2 + dy2 + dz2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<map object at 0x10faa1748>\n"
     ]
    }
   ],
   "source": [
    "points1 = [(1.0,1.0,1.0), (2.0,2.0,2.0), (3.0,3.0,3.0)]\n",
    "points2 = [(4.0,4.0,4.0), (5.0,5.0,5.0), (6.0,6.0,6.0)]\n",
    "\n",
    "distances = map(calc_distance, points1, points2)\n",
    "\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has not done the calculation! Instead it returns an object (an iterator) that would evaluate this computation. But it does so lazily.  To get the answer, we must use the result, for example, by coercing it to a list.\n",
    "\n",
    "This behaviour is **standard** in parallel processing environments, in which the computation may be performed remotely and there may be additional remove computations to perform. By caching the computation, the software environment can sometimes obtain massive efficiency gains.\n",
    "\n",
    "This is how we get the answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.196152422706632, 5.196152422706632, 5.196152422706632]\n"
     ]
    }
   ],
   "source": [
    "print(list(distances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example, this time with multiple arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_smallest(arg1, arg2, arg3):\n",
    "    \"\"\"\n",
    "    Function used to return the smallest value out \n",
    "    of 'arg1', 'arg2' and 'arg3'\n",
    "    \"\"\"\n",
    "\n",
    "    return min(arg1, min(arg2, arg3))\n",
    "\n",
    "a = [1, 2, 3, 4, 5]\n",
    "b = [5, 4, 3, 2, 1]\n",
    "c = [1, 2, 1, 2, 1]\n",
    "\n",
    "result = map(find_smallest, a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 2, 1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHALLENGE: Generalise calc_distance so that it can accept points in any numbers of dimensions.  Generalise find_smallest so that it can accept any number of arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Reducing\n",
    "\n",
    "This is also straightfoward, and exists anagously in R.\n",
    "\n",
    "See http://chryswoods.com/parallel_python/reduce.html\n",
    "\n",
    "Lets start by defining a mapping problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 9, 11, 13, 15]\n"
     ]
    }
   ],
   "source": [
    "def add(x, y):\n",
    "    \"\"\"Function to return the sum of x and y\"\"\"\n",
    "    return x + y\n",
    "\n",
    "a = [1, 2, 3, 4, 5]\n",
    "b = [6, 7, 8, 9, 10]\n",
    "\n",
    "result = map(add, a, b)\n",
    "\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we use reduce to automatically apply addition to the enture set of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "result = map(add, a, b)\n",
    "\n",
    "total = reduce(add, result)\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce has an optional third argument which is the initial value that is used as the first value for the reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "result = map(add, a, b)\n",
    "total = reduce(add, result, 10)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard \"reduce\" function does *not* do anything clever with the computation tree. It simply evaluates the reduction using the sequential definition. That means that it does *not* assume communitivity, which means it can be used with other operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat dog mouse fish\n"
     ]
    }
   ],
   "source": [
    "def join_strings(x, y):\n",
    "    return \"%s %s\" % (x,y)\n",
    "c = [\"cat\", \"dog\", \"mouse\", \"fish\"]\n",
    "\n",
    "result = reduce(join_strings, c)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accumulate vs python\n",
    "\n",
    "Python defines **reduce** to give only the final answer, whereas **accumulate** gives the running total as a list (via an iterator, like map).\n",
    "\n",
    "This is not a universally recognised separation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 16, 27, 40, 55]\n"
     ]
    }
   ],
   "source": [
    "from itertools import accumulate\n",
    "\n",
    "result = map(add, a, b)\n",
    "total = accumulate(result, add)\n",
    "print(list(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat dog', 'cat dog mouse', 'cat dog mouse fish']\n"
     ]
    }
   ],
   "source": [
    "print(list(accumulate(c, join_strings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: parallel implementation\n",
    "\n",
    "multiprocessing python code has to be written into a text file and executed using the python interpreter. It is not recommended to try to run a multiprocessing python script interactively, e.g. via ipython or ipython notebook.\n",
    "\n",
    "This is because the required resources (CPUs) have to be requested from the system and appropriately returned, and the libraries are not reliable across platforms.\n",
    "\n",
    "(it seems to work on linux and mac, but not in windows https://stackoverflow.com/questions/37103243/multiprocessing-pool-in-jupyter-notebook-works-on-linux-but-not-windows)\n",
    "\n",
    "See http://chryswoods.com/parallel_python/multiprocessing.html\n",
    "\n",
    "Multiprocessing achieves parallelism by running multiple copies of your script, it forces you to write it in a particular way. All imports should be at the top of the script, followed by all function and class definitions. This is to ensure that all copies of the script have access to the same modules, functions and classes. Then, you should ensure that only the master copy of the script runs the code by protecting it behind an if __name__ == \"__main__\" statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the following works you should be ok in the notebook; otherwise switch to the scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "def f(x):\n",
    "    return x**2\n",
    "pool = Pool(8)\n",
    "for res in pool.map(f,range(10)):\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script illustrates the key points:\n",
    "\n",
    "* Distributing compute over cores\n",
    "* Detecting the CPU architecture/count\n",
    "* Ensuring the compute is parallelised\n",
    "* Performing process-specific evaluation\n",
    "\n",
    "(Copy into a script and run with python myscript.py if it doesn't run natively.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cores available equals 12\n",
      "Worker 43474 calculating square of 1\n",
      "Worker 43481 calculating square of 15\n",
      "Worker 43479 calculating square of 11\n",
      "Worker 43475 calculating square of 3\n",
      "Worker 43483 calculating square of 19\n",
      "Worker 43476 calculating square of 5\n",
      "Worker 43480 calculating square of 13\n",
      "Worker 43478 calculating square of 9\n",
      "Worker 43485 calculating square of 23\n",
      "Worker 43484 calculating square of 21\n",
      "Worker 43482 calculating square of 17\n",
      "Worker 43477 calculating square of 7\n",
      "Worker 43479 calculating square of 12\n",
      "Worker 43481 calculating square of 16\n",
      "Worker 43476 calculating square of 6\n",
      "Worker 43482 calculating square of 18\n",
      "Worker 43475 calculating square of 4\n",
      "Worker 43477 calculating square of 8\n",
      "Worker 43483 calculating square of 20\n",
      "Worker 43474 calculating square of 2\n",
      "Worker 43478 calculating square of 10\n",
      "Worker 43480 calculating square of 14\n",
      "Worker 43484 calculating square of 22\n",
      "Worker 43479 calculating square of 25\n",
      "Worker 43481 calculating square of 27\n",
      "Worker 43476 calculating square of 29\n",
      "Worker 43485 calculating square of 24\n",
      "Worker 43475 calculating square of 31\n",
      "Worker 43483 calculating square of 33\n",
      "Worker 43477 calculating square of 35\n",
      "Worker 43474 calculating square of 39\n",
      "Worker 43478 calculating square of 37\n",
      "Worker 43482 calculating square of 41\n",
      "Worker 43479 calculating square of 26\n",
      "Worker 43476 calculating square of 30\n",
      "Worker 43481 calculating square of 28\n",
      "Worker 43480 calculating square of 43\n",
      "Worker 43484 calculating square of 45\n",
      "Worker 43483 calculating square of 34\n",
      "Worker 43474 calculating square of 40\n",
      "Worker 43477 calculating square of 36\n",
      "Worker 43485 calculating square of 47\n",
      "Worker 43482 calculating square of 42\n",
      "Worker 43478 calculating square of 38\n",
      "Worker 43475 calculating square of 32\n",
      "Worker 43481 calculating square of 49\n",
      "Worker 43480 calculating square of 44\n",
      "Worker 43484 calculating square of 46\n",
      "Worker 43485 calculating square of 48\n",
      "Worker 43481 calculating square of 50\n",
      "The sum of the square of the first 50 integers is 42925\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from multiprocessing import Pool, cpu_count, current_process\n",
    "\n",
    "def square(x):\n",
    "    \"\"\"Function to return the square of the argument\"\"\"\n",
    "    print(\"Worker %s calculating square of %s\" % (current_process().pid, x))\n",
    "    return x * x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # print the number of cores\n",
    "    print(\"Number of cores available equals %s\" % cpu_count())\n",
    "    N=50\n",
    "    # create a pool of workers\n",
    "    # start all worker processes\n",
    "    pool = Pool(processes= cpu_count())\n",
    "    # create an array of 5000 integers, from 1 to 5000\n",
    "    r = range(1, N+1)\n",
    "    result = pool.map(square, r)\n",
    "\n",
    "    total = reduce(lambda x, y: x + y, result)\n",
    "\n",
    "    print(\"The sum of the square of the first %s integers is %s\" % (N, total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about the order of computation and printing?\n",
    "\n",
    "In general it is a really bad idea to assume that printing appears to the screen in the correct order!\n",
    "\n",
    "(NB: Christopher's code used \"with Pool(processes=nprocs) as pool\" which didn't work for me due to python version issues. Multicore processing is still in active development....)\n",
    "\n",
    "Christopher has an example in which we define a function inside the __main__ loop. This **hangs**  because the worker nodes can't see it!  **CAREFUL** with this sort of thing.\n",
    "\n",
    "However, we can reuse our pool of processes in a straightforward way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cores available equals 12\n",
      "square 3\n",
      "square 2\n",
      "square 1\n",
      "square 4\n",
      "square 5\n",
      "The sum of the square of the first 5 integers is 55\n",
      "The sum of the cube of the first 5 integers is 225\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from multiprocessing import Pool, cpu_count, current_process\n",
    "\n",
    "def square(x):\n",
    "    \"\"\"Function to return the square of the argument\"\"\"\n",
    "    print(\"square\"+\" \"+str(x))\n",
    "    return x * x\n",
    "\n",
    "def cube(x):\n",
    "    \"\"\"Function to return the cube of the argument\"\"\"\n",
    "    return x * x * x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # print the number of cores\n",
    "    print(\"Number of cores available equals %s\" % cpu_count())\n",
    "    N=5\n",
    "    # create a pool of workers\n",
    "    # start all worker processes\n",
    "    pool = Pool(processes= cpu_count()) ## THIS is where all of the memory state is \n",
    "    ## created and all of the processes \"know about\" everything above. So they \"know\" N\n",
    "    ## and hence all compute their own version of r correctly.\n",
    "    \n",
    "    # create an array of 5000 integers, from 1 to N \n",
    "    r = range(1, N+1)\n",
    "    squares = pool.map(square, r)\n",
    "    totalsquares = reduce(lambda x, y: x + y, squares)\n",
    "    print(\"The sum of the square of the first %s integers is %s\" % (N, totalsquares))\n",
    "\n",
    "    cubes = pool.map(cube, r)\n",
    "    totalcubes = reduce(lambda x, y: x + y, cubes)\n",
    "    print(\"The sum of the cube of the first %s integers is %s\" % (N, totalcubes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use mapping on multiple inputs, we have to either:\n",
    "\n",
    "* create a tuple of the arguments\n",
    "* or pass it through using **zip** and switch from the **map** to **starmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 9, 11, 13, 15]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def add(x, y):\n",
    "    \"\"\"Return the sum of the tuple of two arguments\"\"\"\n",
    "    return x + y\n",
    "\n",
    "a = [1, 2, 3, 4, 5]\n",
    "b = [6, 7, 8, 9, 10]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with Pool() as pool:\n",
    "        result = pool.starmap(add, zip(a,b))\n",
    "\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other implementation niggles, such as support for lambda functions (which is missing) etc. These may be addressed in newer versions or alternative packages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: asynchronous functions\n",
    "\n",
    "We saw above that the \"print\" statements were out of order. This is because the threads had to \"race\" to collect the next job, and also race to print to the screen. There is only one job queue and one screen.\n",
    "\n",
    "The following script performs jobs asynchronously. You should see that there are 3 workers, which complete one task before taking the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master process is PID 43358\n",
      "Process 43511 going to sleep for 2 second(s)\n",
      "Process 43510 going to sleep for 1 second(s)\n",
      "Process 43512 going to sleep for 3 second(s)\n",
      "Process 43510 waking up\n",
      "Process 43510 going to sleep for 4 second(s)\n",
      "Process 43511 waking up\n",
      "Process 43511 going to sleep for 5 second(s)\n",
      "Process 43512 waking up\n",
      "Process 43512 going to sleep for 7 second(s)\n",
      "Process 43510 waking up\n",
      "Process 43510 going to sleep for 8 second(s)\n",
      "Process 43511 waking up\n",
      "Process 43512 waking up\n",
      "Process 43510 waking up\n",
      "Result is [1, 2, 3, 4, 5, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from multiprocessing import Pool, current_process\n",
    "\n",
    "def slow_function(nsecs):\n",
    "    \"\"\"\n",
    "    Function that sleeps for 'nsecs' seconds, returning\n",
    "    the number of seconds that it slept\n",
    "    \"\"\"\n",
    "    print(\"Process %s going to sleep for %s second(s)\" % (current_process().pid, nsecs))\n",
    "    # use the time.sleep function to sleep for nsecs seconds\n",
    "    time.sleep(nsecs)\n",
    "    print(\"Process %s waking up\" % current_process().pid)\n",
    "    return nsecs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Master process is PID %s\" % current_process().pid)\n",
    "\n",
    "    with Pool(3) as pool:\n",
    "        r = pool.map(slow_function, [1,2,3,4,5,7,8])\n",
    "\n",
    "    print(\"Result is %s\" % r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we don't want to wait for a computation to be completed before distributing some other computation. In that case we can use \"async\" versions of map (or apply, or whatever)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master process is PID 43358\n",
      "Process 43713 going to sleep for 1 second(s)\n",
      "Process 43714 going to sleep for 2 second(s)\n",
      "Process 43715 going to sleep for 3 second(s)\n",
      "Starting r1 pool\n",
      "Starting r2 pool\n",
      "Process 43713 waking up\n",
      "Process 43713 going to sleep for 4 second(s)\n",
      "Process 43714 waking up\n",
      "Process 43714 going to sleep for 5 second(s)\n",
      "Process 43715 waking up\n",
      "Process 43715 going to sleep for 1 second(s)\n",
      "Process 43715 waking up\n",
      "Process 43715 going to sleep for 2 second(s)\n",
      "Process 43713 waking up\n",
      "Process 43713 going to sleep for 3 second(s)\n",
      "Process 43715 waking up\n",
      "Process 43715 going to sleep for 4 second(s)\n",
      "Process 43714 waking up\n",
      "Process 43714 going to sleep for 5 second(s)\n",
      "Process 43713 waking up\n",
      "Process 43715 waking up\n",
      "Process 43714 waking up\n",
      "Result one is [1, 2, 3, 4, 5]\n",
      "Result two is [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from multiprocessing import Pool, current_process\n",
    "\n",
    "def slow_function(nsecs):\n",
    "    \"\"\"\n",
    "    Function that sleeps for 'nsecs' seconds, returning\n",
    "    the number of seconds that it slept\n",
    "    \"\"\"\n",
    "    print(\"Process %s going to sleep for %s second(s)\" % (current_process().pid, nsecs))\n",
    "    # use the time.sleep function to sleep for nsecs seconds\n",
    "    time.sleep(nsecs)\n",
    "    print(\"Process %s waking up\" % current_process().pid)\n",
    "    return nsecs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Master process is PID %s\" % current_process().pid)\n",
    "\n",
    "    with Pool(3) as pool:\n",
    "        print(\"Starting r1 pool\")\n",
    "        r1 = pool.map_async(slow_function, [1,2,3,4,5])\n",
    "        print(\"Starting r2 pool\")\n",
    "        r2 = pool.map_async(slow_function, [1,2,3,4,5])\n",
    "\n",
    "        r1.wait()\n",
    "        r2.wait()\n",
    "        # if two wait in front of these two code it will be wait until getting all the ans \n",
    "        print(\"Result one is %s\" % r1.get())\n",
    "        r2.wait()\n",
    "        print(\"Result two is %s\" % r2.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asynchronous computation \n",
    "\n",
    "Here we encountered \"futures\" which are computations that may not have completed and therefore may not be available.\n",
    "\n",
    "Futures are a very common variable type in parallel programming across many languages. Futures provide several common functions;\n",
    "\n",
    "* Block (wait) until the result is available. In multiprocessing, this is via the .wait() function, e.g. r1.wait() in the above script.\n",
    "* Retrieve the result when it is available (blocking until it is available). This is the .get() function, e.g. r1.get().\n",
    "* Test whether or not the result is available. This is the .ready() function, which returns True when the asynchronous function has finished and the result is available via .get().\n",
    "* Test whether or not the function was a success, e.g. whether or not an exception was raised when running the function. This is the .successful() function, which returns True if the asynchronous function completed without raising an exception. Note that this function should only be called after the result is available (e.g. when .ready() returns True)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Information\n",
    "\n",
    "There are additional ways to help parallelisation be efficient. One is the idea of \"chunksize\", or how many commands get sent to each worker; it is a parameter of starmap/map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
